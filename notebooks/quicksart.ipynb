{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# phospho Quickstart\n",
    "\n",
    "In this quickstart, we will use the `lab`from the `phospho`package to run an event extraction task on a dataset.\n",
    "First, we will run on a subset of the dataset with several models:\n",
    "- the OpenAI API\n",
    "- the Mistral AI API\n",
    "- a local Ollama model\n",
    "\n",
    "Then, we will use the `lab` optimizer to find the best model and hyperparameters for the task in term of performance, speed and price.\n",
    "\n",
    "Finally, we will use the `lab` to run the best model on the full dataset and compare the results with the subset.\n",
    "\n",
    "Feel free to only use the APIs or Ollama models you want.\n",
    "\n",
    "## Installation and setup\n",
    "\n",
    "You will need \n",
    "- an OpenAI API key (find yours [here](https://platform.openai.com/api-keys))\n",
    "- a Mistral AI API key (find yours [here](https://console.mistral.ai/api-keys/))\n",
    "- Ollama running on your local machine, with the Mistral 7B model installed. You can find the installation instructions for Ollama [here](https://ollama.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and check env variables\n",
    "import os\n",
    "\n",
    "# Check the environment variables\n",
    "assert os.getenv(\"OPENAI_API_KEY\") is not None, \"You need to set the OPENAI_API_KEY environment variable\" \n",
    "assert os.getenv(\"MISTRAL_API_KEY\") is not None, \"You need to set the MISTRAL_API_KEY environment variable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in /Users/plb/Documents/phospho/code/clients/phospho/.venv/lib/python3.9/site-packages (0.1.6)\n",
      "Requirement already satisfied: httpx<0.26.0,>=0.25.2 in /Users/plb/Documents/phospho/code/clients/phospho/.venv/lib/python3.9/site-packages (from ollama) (0.25.2)\n",
      "Requirement already satisfied: anyio in /Users/plb/Documents/phospho/code/clients/phospho/.venv/lib/python3.9/site-packages (from httpx<0.26.0,>=0.25.2->ollama) (4.3.0)\n",
      "Requirement already satisfied: certifi in /Users/plb/Documents/phospho/code/clients/phospho/.venv/lib/python3.9/site-packages (from httpx<0.26.0,>=0.25.2->ollama) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/plb/Documents/phospho/code/clients/phospho/.venv/lib/python3.9/site-packages (from httpx<0.26.0,>=0.25.2->ollama) (1.0.4)\n",
      "Requirement already satisfied: idna in /Users/plb/Documents/phospho/code/clients/phospho/.venv/lib/python3.9/site-packages (from httpx<0.26.0,>=0.25.2->ollama) (3.6)\n",
      "Requirement already satisfied: sniffio in /Users/plb/Documents/phospho/code/clients/phospho/.venv/lib/python3.9/site-packages (from httpx<0.26.0,>=0.25.2->ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/plb/Documents/phospho/code/clients/phospho/.venv/lib/python3.9/site-packages (from httpcore==1.*->httpx<0.26.0,>=0.25.2->ollama) (0.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/plb/Documents/phospho/code/clients/phospho/.venv/lib/python3.9/site-packages (from anyio->httpx<0.26.0,>=0.25.2->ollama) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1 in /Users/plb/Documents/phospho/code/clients/phospho/.venv/lib/python3.9/site-packages (from anyio->httpx<0.26.0,>=0.25.2->ollama) (4.10.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " It's important to note that the \"best\" French cheese can be subjective as it depends on personal preferences. There are numerous varieties of French cheese, each with its unique taste, texture, and character. Here are some popular French cheeses that are highly regarded and loved by many:\n",
      "\n",
      "1. Roquefort: A blue-veined sheep's milk cheese from the Massif Central region in France. It is known for its pungent aroma and sharp, tangy flavor.\n",
      "2. Comté: A nutty and savory cow's milk cheese from the Franche-Comté region. It has a rich, buttery texture and a slightly sweet taste.\n",
      "3. Camembert: A soft, white, cow's milk cheese with a strong, pungent aroma and a creamy, tangy taste. Originating from Normandy, it is often aged in wooden boxes.\n",
      "4. Brie de Meaux: A popular soft, bloomy rind cheese made from cow's milk, originating from the Marne region. It has a mild, buttery flavor and a velvety texture.\n",
      "5. Munster: A pungent, washed-rind, cow's milk cheese from Alsace. Its texture is soft and gooey with a strong, spicy, garlic-like aroma and taste.\n",
      "6. Morbier: A semi-hard, cow's milk cheese with a distinctive layer of ash running through the middle. It has a mild, nutty flavor with earthy undertones.\n",
      "7. Reblochon: A bloomy rind, cow's milk cheese from the Rhône Alpes region. It has a strong aroma and a rich, creamy texture with a slightly sweet and tangy taste.\n",
      "8. Époisses: A soft, bloomy rind, cow's milk cheese from Burgundy. It is known for its pungent smell and complex, savory flavors with a hint of garlic.\n",
      "\n",
      "Ultimately, the \"best\" French cheese will depend on your personal taste preferences! You may want to try a few different varieties to discover which one you enjoy the most.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "# Let's check we can reach your local Ollama API\n",
    "response = ollama.chat(model='mistral', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'What is the best French cheese?',\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the phospho workload and jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/plb/Documents/phospho/code/clients/phospho/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'job_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the meaning of life?\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Prompt to use for the model \u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Add a job to it\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m myWorkload\u001b[38;5;241m.\u001b[39madd_job(\u001b[43mJob\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevent-detection\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt_to_bool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmyConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'job_id'"
     ]
    }
   ],
   "source": [
    "from phospho import lab\n",
    "from typing import Literal\n",
    "\n",
    "# Create a workload in our lab\n",
    "workload = lab.Workload()\n",
    "\n",
    "# Setup the configs for our job\n",
    "class EventConfig(lab.JobConfig):\n",
    "    event_name: str\n",
    "    event_description: str\n",
    "    model: Literal[\"openai:gpt-3.5-turbo\", \"mistral:mistral-large-latest\", \"mistral:mistral-small-latest\", \"ollama:mistral-7B\"] = \"openai:gpt-3.5-turbo\"\n",
    "\n",
    "# Add our job to the workload\n",
    "workload.add_job(\n",
    "    lab.Job(\n",
    "        name=\"sync_event_detection\",\n",
    "        id=\"question_answering\",\n",
    "        config=EventConfig(\n",
    "            event_name=\"Question Answering\",\n",
    "            event_description=\"User asks a question to the assistant\",\n",
    "            model=\"openai:gpt-3.5-turbo\"\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cc51d2a908a847f5b705b3d65b55248b': {'event-detection': JobResult(created_at=1709001069, job_id='prompt_to_bool', result_type=<ResultType.bool: 'bool'>, value=False, logs=['What is the meaning of life?', 'The'], metadata={})},\n",
       " 'd46eeb1e5fdc4eca9a1a628db685eed4': {'event-detection': JobResult(created_at=1709001069, job_id='prompt_to_bool', result_type=<ResultType.bool: 'bool'>, value=False, logs=['What is the meaning of life?', 'The'], metadata={})}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from phospho import lab\n",
    "messages = [\n",
    "    lab.Message(\n",
    "        content=\"Hey there!\",\n",
    "    ),\n",
    "    lab.Message(\n",
    "        content=\"How are you?\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "myWorkload.run(messages=messages, executor_type=\"sequential\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a_job \u001b[38;5;241m=\u001b[39m \u001b[43mJob\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevent-detection\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt_to_bool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmyConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDo you like ice cream? \u001b[39;49m\u001b[38;5;132;43;01m{message_content}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'params'"
     ]
    }
   ],
   "source": [
    "a_job = Job(\n",
    "    job_id=\"event-detection\",\n",
    "    job_function=job_library.prompt_to_bool,\n",
    "    job_config=myConfig(),\n",
    "    params={\n",
    "        \"prompt\": \"Do you like ice cream? {message_content}\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Job(\n",
       "  job_id=event-detection,\n",
       "  job_name=prompt_to_bool,\n",
       "  params={\n",
       "    prompt: Do you like ice cream? {message_content}\n",
       "  }\n",
       " )"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[myConfig(model='gpt-3.5-turbo')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_job.job_configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
